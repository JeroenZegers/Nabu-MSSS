[trainer]
#type of loss that should be used
loss_type = deepattactornet
#link the input names defined in the classifier config to sections defined in
#the database config
features = 
#a space seperated list of target names used by the trainer
targets = binary_targets usedbins 
#a mapping between the target names and database sections
binary_targets =  
#a mapping between the target names and database sections
usedbins = 

#if set to True training will resume from latest checkpoint
resume_training =
#a space separated list of different semgent lengths that will be used. Expecting 'full' to be the last one.
#Normally a network for a specific segment length is initliazed with the network of the previous segment length
segment_lengths = 
#number of passes over the entire database
num_epochs =
#initial learning rate of the neural net
initial_learning_rate =
#exponential weight decay parameter
learning_rate_decay =
#cliping value for gradients
clip_grad_value = 
#size of the minibatch (#utterances)
batch_size =
#number of minibatches to aggregate before updating the parameters if 0
#asstnchronous training will be done
numbatches_to_aggregate =

#the data will be divided into buckets according to sequence length, this
#setting determines the number of buckets to use. For no bucketing set to 1
numbuckets = 

###VALIDATION PART###
#frequency of evaluating the validation set.
valid_frequency = 50
#if you want to adapt the learning rate based on the validation set, set to True
valid_adapt = False
#if you want to go back in training if validation performance is worse set to True
go_back = False
#the number of times validation performance can be worse before terminating training, set to None to disable early stopping
num_tries = 3
#set to True if you want to reset the number of tries if the validation performance is better
reset_tries = True
